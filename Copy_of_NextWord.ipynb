{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u1cMYc24S7o"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV8rXQ8H4N09"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH_j1bUA4f2l"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import sys\n",
        "import heapq\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "from numpy.core.multiarray import dtype\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM, Dropout\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from pylab import rcParams\n",
        "matplotlib.use('agg')\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETNQUo5J46ob"
      },
      "source": [
        "path = '/content/drive/MyDrive/ML/NLP/Sequential/NLPDemo.txt'\n",
        "text = open(path).read().lower()\n",
        "print('length of the corpus is: :', len(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "id": "xmfgd1RPT07j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "print (\"unique chars: \",len(chars))"
      ],
      "metadata": {
        "id": "1nR2xHt7Quos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQUENCE_LENGTH = 39\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - SEQUENCE_LENGTH, step):\n",
        "    sentences.append(text[i:i+SEQUENCE_LENGTH])\n",
        "    next_chars.append(text[i+SEQUENCE_LENGTH])\n",
        "print ('num training examples: ',len(sentences))"
      ],
      "metadata": {
        "id": "0PCrwZsoQ4Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "metadata": {
        "id": "Jh7nsEVTRF8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential();\n",
        "model.add(LSTM(128, input_shape=(SEQUENCE_LENGTH, len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "2QmsIg9kRNlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxTwxmCO5K-o"
      },
      "source": [
        "optimizer = RMSprop(lr= 0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(X, y, validation_split=0.05, batch_size=128, epochs=500, shuffle=True).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oeLuWxj6BVd"
      },
      "source": [
        "plt.plot(history['accuracy'])\n",
        "plt.plot(history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc= 'upper left')\n",
        "#plt.savefig(\"01.Accuracy.png\")\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-WVOcVW8IAD"
      },
      "source": [
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc= 'upper left')\n",
        "#plt.savefig(\"02.Loss.png\")\n",
        "plt.show\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gjIPy2D-860"
      },
      "source": [
        "def prepare_input(text):\n",
        "    x = np.zeros((1, SEQUENCE_LENGTH, len(chars)))\n",
        "    for t, char in enumerate(text):\n",
        "        x[0, t, char_indices[char]] = 1\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia1WMKN3BkgK"
      },
      "source": [
        "def sample(preds, top_n = 3):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg_xsreE_o5x"
      },
      "source": [
        "def predict_completion(text):\n",
        "    original_text = text\n",
        "    generalised = text\n",
        "    completion = ''\n",
        "    while True:\n",
        "        x = prepare_input(text)\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(preds, top_n=1)[0]\n",
        "        next_char = indices_char[next_index]\n",
        "        text = text[1:] + next_char\n",
        "        completion += next_char\n",
        "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
        "           return completion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_completions(text, n = 3):\n",
        "    x = prepare_input(text)\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_indices = sample(preds, n)\n",
        "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]"
      ],
      "metadata": {
        "id": "raban0kEUauB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test quote \n",
        "quotes = [\n",
        "    \"this process of prediction is one of the applications nlp deals with. we have made huge progress here  \"\n",
        "]"
      ],
      "metadata": {
        "id": "0EXp2ygtUfKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for q in quotes:\n",
        "    seq = q[:SEQUENCE_LENGTH].lower()\n",
        "    print (seq)\n",
        "    print (predict_completions(seq, 2))\n",
        "    print ()"
      ],
      "metadata": {
        "id": "OYUA90yVUnwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lUsECV28hKgN"
      }
    }
  ]
}